
# Tweet Project â€“ Classification automatique de Tweets (TP Test Unitaire)

## ğŸš€ Objectif
Construire un pipeline complet de Data Science pour la classification automatique de tweets (catastrophes vs normaux), en respectant les bonnes pratiquesâ€¯: nettoyage, modÃ©lisation, tests unitaires, reproductibilitÃ© et dockerisation.

## ğŸ—‚ï¸ Structure du projet

```
tweet_project/
â”œâ”€â”€ data/                # DonnÃ©es brutes (ex : tweets.csv)
â”œâ”€â”€ notebooks/           # Analyses exploratoires et modÃ©lisation
â”‚   â”œâ”€â”€ 01_EDA.ipynb     # Analyse exploratoire des donnÃ©es
â”‚   â””â”€â”€ 02_Preprocessing_Modeling.ipynb  # PrÃ©traitement & ModÃ©lisation
â”œâ”€â”€ src/                 # Code source (prÃ©traitement, pipeline sklearn)
â”‚   â”œâ”€â”€ preprocessing.py # Fonctions de nettoyage et NLP
â”‚   â””â”€â”€ modeling.py      # Pipeline sklearn et Ã©valuation
â”œâ”€â”€ tests/               # Tests unitaires (Pytest)
â”œâ”€â”€ main.py              # Script principal (exÃ©cution du pipeline complet)
â”œâ”€â”€ requirements.txt     # DÃ©pendances Python
â”œâ”€â”€ Dockerfile           # Conteneurisation du projet
â””â”€â”€ README.md            # Ce fichier
```

## ğŸ“¦ Installation & PrÃ©requis
1. **Cloner le dÃ©pÃ´t**
   ```bash
   git clone <url-du-repo>
   cd tweet_project
   ```
2. **Installer les dÃ©pendances**
   ```bash
   pip install -r requirements.txt
   ```
3. **TÃ©lÃ©charger les ressources NLTK** (Ã  faire une seule fois)
   ```python
   import nltk
   nltk.download('stopwords')
   nltk.download('punkt')
   ```
4. **(Optionnel) Utiliser Docker**
   ```bash
   docker build -t tweet_project .
   docker run -it tweet_project
   ```

## ğŸ” FonctionnalitÃ©s principales
- **Exploratory Data Analysis (EDA)** :
  - Statistiques descriptives, analyse des classes, valeurs manquantes, distribution des longueurs de texte, visualisations (WordCloud, histogrammesâ€¦)
- **PrÃ©traitement du texte** :
  - Nettoyage (minuscule, suppression URLs, ponctuation, chiffres, mots courts)
  - Suppression des stopwords (anglais + personnalisÃ©s)
  - Tokenisation, pipeline complet prÃªt pour la modÃ©lisation
- **ModÃ©lisation & Pipeline** :
  - Pipeline scikit-learn (TfidfVectorizer + LogisticRegression)
  - SÃ©paration train/test, Ã©valuation (accuracy, precision, recall, f1-score)
  - Prise en charge des cas particuliers (texte vide, classes dÃ©sÃ©quilibrÃ©esâ€¦)
- **Tests unitaires** :
  - Couverture complÃ¨te du prÃ©traitement, robustesse du pipeline, intÃ©gration sur donnÃ©es rÃ©elles
- **ReproductibilitÃ© & QualitÃ©** :
  - Code modulaire, tests automatisÃ©s, dockerisation

## ğŸ§ª Lancer les tests
Dans le dossier du projetâ€¯:
```bash
pytest
```

## â–¶ï¸ ExÃ©cuter le pipeline principal
```bash
python main.py
```

## ğŸ““ Utilisation des notebooks
Ouvrir les notebooks dans VS Code ou Jupyter pour explorerâ€¯:
- `notebooks/01_EDA.ipynb` : analyse exploratoire
- `notebooks/02_Preprocessing_Modeling.ipynb` : pipeline de prÃ©traitement et modÃ©lisation

## ğŸ“ Exemple dâ€™utilisation du pipeline (dans main.py)
```python
from src.modeling import train_and_evaluate
import pandas as pd
df = pd.read_csv("data/tweets.csv")
pipeline, metrics = train_and_evaluate(df)
print(metrics)
```

## ğŸ› ï¸ Personnalisation
- Ajouter vos propres stopwords dans `src/preprocessing.py` (variable `CUSTOM_STOPWORDS`)
- Modifier le modÃ¨le ou la vectorisation dans `src/modeling.py`
- Ajouter dâ€™autres tests dans le dossier `tests/`

## ğŸ“š Ressources utiles
- [Documentation scikit-learn](https://scikit-learn.org/stable/)
- [NLTK](https://www.nltk.org/)
- [Pytest](https://docs.pytest.org/)

## ğŸ‘¨â€ğŸ’» Auteurs
Projet rÃ©alisÃ© dans le cadre du TP de Test Unitaire (M1 Data Science)
